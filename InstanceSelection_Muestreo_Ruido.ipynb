{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10afec67b3228597",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Scikit-learn e Imbalanced-learn para problemas de clasificación no balanceados, selección de instancias y eliminación de ruido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-174f93495ac61f82",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Técnicas de muestreo para problemas de clasificación no balanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2e6287ef304fb864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Para realizar los diferentes tipos de muestreo vamos a utilizar un librería de Python llamada [**imbalanced-learn**](https://pypi.python.org/pypi/imbalanced-learn). Esta librería no es nativa de Scikit-learn pero es totalmente compatible. Por este motivo la podemos utilizar al igual que todas las funcionalidades de Scikit-learn. La [*API*](https://imbalanced-learn.org/stable/references/index.html#api) (se muestran todas las clases y sus características) para los métodos de muestreo para problemas de clasificación no balanceados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a584db317b5d2127",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "En primer lugar vamos a comentar la **técnica RUS**. La clase correspondiente a dicha técnica se llama [**RandomUnderSampler**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    rus = RandomUnderSampler(sampling_strategy=estrategia, random_state=semilla,replacement=reemplazo)\n",
    "\n",
    "Los parámetros de entrada del método son:\n",
    "* estrategia: determina la forma de realizar el remuestreo. Puede tomar diversos valores:\n",
    "    * Número real (entre 0 y 1): determina el ratio entre el número de ejemplos de la clase minoritaria sobre el de la clase mayoritaria ($\\frac{NumEjClasMin}{NumEjClasMay}$) tras realizar el remuestreo.\n",
    "    * String: determina la clase a ser remuestreada. Las opciones son:\n",
    "        * 'majority': remuestrea solamwente la clase mayoritaria\n",
    "        * 'not minority': remuestrea todas las clases menos la minoritaria.\n",
    "        * 'not majority': remuestrea todas las clases menos la mayoritaria.\n",
    "        * 'all': remuestrea todas las clases (en este caso al número de ejemplos de la clase que tenga menos).\n",
    "        * 'auto': equivale a 'not minority'. Opción por defecto.\n",
    "    * Diccionario: determina el número de ejemplos (valor) a obtener tras aplicar el remuestreo de cada clase (clave).\n",
    "* reemplazo: valor booleano que determina si el muestreo se realiza con reemplazamiento o no. Por defecto está a False.\n",
    "* semilla: valor que determina la semilla a utilizar para garantizar la reproducibilidad de los resultados.\n",
    "\n",
    "Una vez generado el objeto de la clase RandomUnderSampler se pueden ejecutar los siguientes métodos:\n",
    "* fit: realiza el aprendizaje. Se le pasan como parámetros de entrada tanto los datos de entrada (X) como los de salida (y).\n",
    "* fit_resample: realiza el aprendizaje y después aplica el remuestreo del dataset. Se le pasan como parámetros de entrada tanto los datos de entrada (X) como los de salida (y).\n",
    "\n",
    "NOTA IMPORTANTE: las clases para realizar muestreo no tiene método resample solo. El motivo es que de este modo queda claro que solamente se puede aplicar estas técnicas para entrenar, con los datos de entrenamiento, y nunca en caso contrario (conjuntos de validación y test o cuando se invoca el método *predict* de una Pipeline).\n",
    "\n",
    "Los parámetros de salida del método sample son:\n",
    "* X_sampled: variables de entrada muestreadas.\n",
    "* y_sampled: variable de salida muestreada.\n",
    "\n",
    "Además, se puede acceder a la lista de índices con los ejemplos muestreados (seleccionados) mediante el atributo *sample_indices_* del objeto de la clase entrenado y con el que se ha hecho el muestreo (*fit_resample*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1523f8930a4e546e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Técnica Tomek Links**, su clase se llama [**TomekLinks**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    TomekLinks(sampling_strategy=estrategia)\n",
    "\n",
    "La explicación del argumento de entrada, los métodos del objeto generado y las salidas de la técnica son las mismas que hemos explicado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e253219abe012964",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Técnica CNN**, su clase se llama [**CondensedNearestNeighbour**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.CondensedNearestNeighbour.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    CondensedNearestNeighbour(sampling_strategy=estrategia, n_neighbors=numeroVecinos, random_state=semilla)\n",
    "\n",
    "Hay un nuevo argumento de entrada que es \n",
    "* numeroVecinos: determina el número de vecinos a tener en cuenta, por defecto es 1 (None).\n",
    "\n",
    "El resto de parámetros de entrada, los métodos del objeto generado y las salidas de la técnica son las mismas que hemos explicado anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e35e71db14d23ee2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Técnica OSS**, su clase se llama [**OneSidedSelection**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.OneSidedSelection.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    OneSidedSelection(sampling_strategy=estrategia, n_neighbors=numeroVecinos, random_state=semilla)\n",
    "\n",
    "Los parámetros de entrada, los métodos del objeto generado y las salidas de la técnica son las misma que hemos explicado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e6a633a3c9b98a85",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Técnica NCL**, su clase se llama [**NeighbourhoodCleaningRule**](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NeighbourhoodCleaningRule.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    NeighbourhoodCleaningRule(sampling_strategy=estrategia, n_neighbors=numeroVecinos)\n",
    "\n",
    "Los argumentos de entrada, los métodos del objeto generado y las salidas de la técnica son las misma que hemos explicado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-190e41682f34ff77",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Técnica ROS**, su clase se llama [**RandomOverSampler**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    RandomOverSampler(sampling_strategy=estrategia, random_state=semilla)\n",
    "\n",
    "Los argumentos de entrada, los métodos del objeto generado y las salidas de la técnica son las mismas que hemos explicado anteriormente. Al ser una técnica de over-sampling, no tiene mucho sentido obtener los ejemplos muestreados y la opción por defecto del argumento *sampling_strategy* pasa a ser *not majority*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bfbfc5dc503adf7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Técnica SMOTE**, su clase se llama [**SMOTE**](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    SMOTE(sampling_strategy=estrategia, n_neighbors=numeroVecinos, random_state=semilla)\n",
    "\n",
    "Los argumentos de entrada, los métodos del objeto generado y las salidas de la técnica son las mismas que hemos explicado anteriormente. La opción por defecto del argumento *sampling_strategy* pasa a ser *not majority*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73a5d7e229ab1ac3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Técnica híbrida SMOTE con Tomek Links**, su clase se llama [**SMOTETomek**](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTETomek.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    SMOTETomek(sampling_strategy=estrategia, random_state=semilla)\n",
    "\n",
    "Los argumentos de entrada, los métodos del objeto generado y las salidas de la técnica son las mismas que hemos explicado anteriormente. La opción por defecto del argumento *sampling_strategy* pasa a ser *not majority*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e6e89616e73848c3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Técnica híbrida SMOTE con ENN**, su clase se llama [**SMOTEENN**](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html). La llamada al constructor de la clase y sus principales parámetros son los siguientes:\n",
    "\n",
    "    SMOTEENN(sampling_strategy=estrategia, random_state=semilla)\n",
    "    \n",
    "El parámetro de entrada, los métodos del objeto generado y las salidas de la técnica son las misma que hemos explicado anteriormente. La opción por defecto del argumento *sampling_strategy* pasa a ser *not majority*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11433e711ab752b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Al igual que hemos visto en prácticas anteriores, podemos crear un flujo de técnicas a aplicar para resolver el problema. Para ello se utilizan las **Pipelines**. \n",
    "\n",
    "En este caso, los clases de las técnicas de muestreo no tienen el método *transform* sino que tienen el método *fit_resample*. Por ello, las pipelines de Scikit-learn no nos valen y tenemos que utilizar las [*Pipelines*](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html) de la librería imbalanced-learn (funcionan igual que las de Scikit-learn pero también dan soporte a los métodos de imbalanced-learn).\n",
    "\n",
    "    from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0e5838d78b018c22",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Las medidas de rendimiento para evaluar problemas de clasificación no balanceados son diferentes al accuracy. Unas de las más habituales son:\n",
    "* Media geométrica entre el porcentaje de aciertos de la clase positiva y el de la negativa. Para obtener dicho redimiento se debe utilizar la función [*geometric_mean_score*](https://imbalanced-learn.org/stable/references/generated/imblearn.metrics.geometric_mean_score.html) ofrecida en la librería *imblearn.metrics*. \n",
    "* Fscore, que es la media harmónica entre el porcentaje de ejemplos correctamente clasificados de la clase positiva y el porcentaje de ejemplos acertados cuando el clasificador predice clase positiva. La clase de *Scikit-learn* para obtener el Fscore se lama [*f1_score*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html).\n",
    "\n",
    "También se puede ver un resumen del rendimiento, dado por varias métricas, en cada clase y en global (macro: media aritmética: weighted: media poderada por el porcentaje de ejemplos de cada clase). Para ello, se puede utilizar la función [*classification_report_imbalanced*](https://imbalanced-learn.org/stable/references/generated/imblearn.metrics.classification_report_imbalanced.html) ofrecida en la librería *imblearn.metrics*. \n",
    "    \n",
    "Los parámetros de entrada de todas las funciones son los mismos que para la función *accuracy_score*. Es decir, las clases reales y las clases predichas por el clasificador (en ese orden)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1f42cd423852fde0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Técnicas de selección de instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8fbe190020ad2695",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Para realizar procesos de selección de instancias podemos utilizar las técnicas de muestreo de datos para problemas de clasificación no balanceados. En concreto, se puede utilizar las técnicas que valgan tanto para acometer dicho muestreo como para realizar selección de instancias (independientemente de la clase) que estén implementadas en *imbalanced-learn*. Para ello, lo único que se debe determinar en el constructor es la estrategia de muestreo, parámetro *sampling_strategy* de las clases enteriores al que se debe asginar el valor *all*. De este modo muestreará los ejemplos de todas las clases (todos los ejemplos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d41adb73f36590f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Técnicas de eliminación de ruido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e06eba97f0f320ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Como hemos comentado en clase de teoría, algunas de las técnicas de selección de instancias están centradas en eliminar ruido. Por tanto, lo comentado en el apartado anterior sería válido. No obstante, vamos a describir más en concreto 3 técnicas:\n",
    "* [*Tomek Links*](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html), cuya clase ha sido explicada anteriormente. Lo único que hay que modificar para que realice un proceso de eliminación de ruido es que elimine ejemplos de las dos clases. Para ello, se debe asignar el parámetro *sampling_strategy* a *all*.\n",
    "* [*EditedNearestNeighbours*](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html) (ENN). La clase es similar a las comentadas en los métodos de under-sampling. Para que funcione como método de eliminación de ruido se debe elegir la misma estragia de muestreo que se ha explicado con Tomek Links y para que funcione como se ha explicado en clase de teoría se debe establecer el parámetro *kind_sel* a *mode*, es decir, eliminará un ejemplo cuando se falle (no hace falta que todos sean de la misma clase que el ejemplo a estudiar, con que se falle es suficiente). También se podría variar el número de vecinos a considerar mediante el parámetro *n_neighbors*, cuyo valor por defecto es 3.\n",
    "* [*AllKNN*](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.AllKNN.html). La clase es similar a las comentada para ENN y los parámetros se deben fijar del mismo modo."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py38ml] *",
   "language": "python",
   "name": "conda-env-.conda-py38ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
